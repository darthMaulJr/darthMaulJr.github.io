<html>
<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="chrome=1">
	<title>Sreejith Sreekumar</title>

	<link rel="stylesheet" href="stylesheets/styles.css">
	<link rel="stylesheet" href="stylesheets/pygment_trac.css">
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
	<script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>
<body>
	<div class="wrapper">
		<header>
			<h1>Sreejith Sreekumar</h1>
		</header>

		<section>
			<p><h4>Hi! I am Sreejith. </h4> </p>
			
			<p>
			  I am currently a graduate student of Data Science at <a href="https://www.northeastern.edu/">Northeastern University</a>, and a graduate student researcher in Network Science at <a href="https://www.barabasilab.com">Barabasi Lab</a>.
			</p>

			<p>
				Math and Machine Learning (Bayesian Methods and Reinforcement Learning) are the subjects which fascinate me the most. Occasionally I spend time reading/listening to Physics/Astronomy lectures. I love the <a href="https://en.wikipedia.org/wiki/Unix_philosophy">Linux philosophy</a> and <a href="https://en.wikipedia.org/wiki/Open-source_software">Open Source Technologies</a>.
			</p>

			<p>
				This is where I scribble stuff:  <a href="https://github.com/srjit">Github</a>, and <a href="https://sourcerer.io/srjit">this</a> is an overview of what/how I do it.
			</p>

			<p>
				You can find me here in <a href="https://in.linkedin.com/in/sreejith2904">Linkedin</a> and on <a href="https://twitter.com/srjit_">Twitter.</a> 
			</p>

			<p>
				And you'll find my resume <a href="https://github.com/srjit/resume-singlepage/blob/master/awesome-cv/resume.pdf">here</a>.
			</p>

			<p> 
				Feel free to contact me at <a href="mailto:sreejith2904@gmail.com">sreejith2904@gmail.com</a> or <a href="sreekumar.s@husky.neu.edu">sreekumar.s@husky.neu.edu</a>
			</p>

			<h3> Recent Updates </h3>

			<p>
			  I have joined <a href="https://www.barabasilab.com">Barabasi Lab</a> in the <a href="https://www.networkscienceinstitute.org/">Centre for Complex Networks Research</a>, Northeastern University as a graduate student researcher where I am advised by <a href="http://barabasi.com/">Prof. Albert-László Barabási</a> and <a href="https://www.barabasilab.com/people/alexander-gates">Dr. Alexander Gates</a>.
			</p>

			<p>
			  During the <i>Spring and Summer of 2018</i>, I interned at <a href="https://www.fidelity.com/">Fidelity Investments</a> as a Data Scientist(Co-Op). 
			</p>  
			<p>
			  I was a Research Assistant during the <i>Fall of 2017</i>, working with <a href="http://www.damore-mckim.northeastern.edu/faculty/h/hoitash-udi">Prof. Udi Hoitash</a> for building quantitative models to measure accounting consistency based on text similarity.
			</p>

			<h3> What have I been up to lately? </h3>

			<p>
			  <a href="https://github.com/srjit/pointer-seq2seq-gun-violence-event-analysis"><b>Investigating Instances of Gun Violence using Pointer Networks</b></a> <br/>
			  Proposed a novel model that exploits the power of Attention Mechanism in Sequence-to-Sequence learning and Pointer Neural Nets to extract the attributes of gun violence events from news reports.
			</p>
			
			<p>
				<a href="https://github.com/srjit/lstm-sentence-similarity"><b>Quantifying Semantic Similarity of Sentences using Long Short-Term Memory Neural Nets</b></a> <br/>
				Using vectorized representations from Glove embeddings, the deep LSTM network designed could classify semantically similar questions from the ones which are not. The network was trained on an NVIDIA GeForce GTX 950 GPU and an accuracy of 83% was obtained. 
			</p>

			<p>
				<a href="https://github.com/srjit/rcnn-tensorflow/tree/master/alexnet"><b>Domain Specific Classification using AlexNet</b></a><br/>
				Tuned the layers of a pre-trained AlexNet model for binary classification task on images that obtained an accuracy of 94% for the new task.
			</p>

			<p>
				<a href="https://github.com/srjit/kaggle-scripts"><b>Home Value Prediction</b></a><br/>
				Modeled Zillow’s house rent prediction problem using Microsoft’s LightGBM algorithm with a mean absolute error of 0.064.
			</p>


			<p>
				<a href="https://github.com/srjit/fakenewschallange"><b>The Fake News Stance Classification</b></a> <br/>
				We address the problem of identifying fake news from authentic ones as a classification task, trying to measure the degree of relatedness between the headline and the article in discrete levels called stances. The relatedness in our task was defined on four levels - namely agree, discuss, disagree, unrelated. With a number of handcrafted linguistic features along with distance features from vectorized (Word2Vec) fields (header and article), we were able to obtain a maximum classification accuracy of 88%. Random Forests, Support Vector Machines and XGBoost algorithms were used for performance comparison.
			</p>

			<h3> Here are some projects which I worked on before joining back school for my graduate studies...  </h3>

			<p>
				<b>Natural Language Workbench</b><br/>
				I worked with the Speech Science team at Innovation Labs, [24]7 Inc for modeling chat transcripts from customer conversations and use it to identify the user intent of a customer care call.
				The whole modeling process pipeline was constructed on a PySpark pipeline and was scaled on a Spark cluster on Hadoop.  
			</p>

			<p>
				<b>Prediction as a Service</b> <br/>
				Developed components of a modeling tool for building customer propensity machine learning models, which classifies customers as hot leads during a web journey. The tool uses HP
				Vertica as its backend for data processing, and it’s native support for R user-defined-functions for algorithm integration.
			</p>

			<p>
				<b>Campaign Funnel Automation for HDFC Bank</b> <br/>
				Campaign funnel automation involves automating and analyzing the success rate of campaigns organized by HDFC bank across different channels like ATM, Netbanking, Emails, and SMS. Data gathering across databases via Apache Sqoop, transformation and processing via Apache Spark jobs are integral processes in the system.
			</p>

			<p>
				<b> TURF Artificial Intelligence (Rebranded as <a href="http://www.xurmo.com/xurmo-platform.html"><b>Xurmo Platform</b></a>) </b> <br/>
				Turf Ai is a platform for big data analytics, offering data intake from structured and unstructured data sources, data transformation components, combined with a variety of
				visualization and analytical tools to help identify, analyze and predict patterns.
			</p>

			<p>
				<b> Insight </b> <br/>
				Insight is an enterprise knowledge discovery application. Insights gleaned by analysts via their experiences aren’t being effectively captured because of loss of information due
				to storing data in individual analyst systems, and employee churn. Insight parses emails, chats, documents and other metadata on local machines and CMS systems to recommend the People, Documents and Conversations that could answer users’ query.
			</p>

			<h3> Where have I left my footprints? </h3>
			<ul>
				<li>Senior Data Engineer, Data Science Group, <a href="https://www.247-inc.com/">Innovation Labs [24]7 Inc.</a> (Jun 2016 - Dec 2017)</li>
				<li>Data Engineer, Data Science Group, <a href="https://www.247-inc.com/">Innovation Labs [24]7 Inc. </a> (May 2015 - Jun 2016)</li>
				<li>Software Engineer, <a href="http://www.xurmo.com/">Xurmo Technologies Pvt. Ltd.</a> (Jan 2012 - Apr 2015)</li>
				<li>Intern, <a href="http://www.xurmo.com/">Xurmo Technologies Pvt. Ltd.</a> (Jul 2011 - Jan 2012)</li>
				<li>Undergrad in Computer Science, <a href="http://gectcr.ac.in/">Government Engineering College, Thrissur</a> (Sep 2007 - May 2011)</li>
			</ul>
		</section>	      	

		<footer>
			<p>Maintained by <a href="mailto:sreekumar.s@husky.neu.edu">sreekumar.s@husky.neu.edu</a></p>
			<p><small>Theme modified from <a href="https://github.com/orderedlist">orderedlist</a></small></p>
		</footer>

	</div>

	<script type="text/javascript">
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-100200526-1', 'auto');
		ga('send', 'pageview');
	</script>

</body>
</html>
